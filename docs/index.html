
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Model Compression Toolkit User Guide &#8212; MCT Documentation: ver 1.6.0</title>
    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/scrolls.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />
    <link rel="stylesheet" href="_static/print.css" type="text/css" />
    
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/theme_extras.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Visualization within TensorBoard" href="guidelines/visualization.html" /> 
  </head><body>
    <div id="content">
      <div class="header">
        <h1 class="heading"><a href="#"
          title="back to the documentation overview"><span>Model Compression Toolkit User Guide</span></a></h1>
      </div>
      <div class="relnav" role="navigation" aria-label="related navigation">
        <a href="#">Model Compression Toolkit User Guide</a>
        | <a href="guidelines/visualization.html">Visualization within TensorBoard &raquo;</a>
      </div>
      <div id="contentwrapper">
        <div id="toc" role="navigation" aria-label="table of contents navigation">
          <h3>Table of Contents</h3>
          <ul>
<li><a class="reference internal" href="#">Model Compression Toolkit User Guide</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#install">Install</a></li>
<li><a class="reference internal" href="#supported-features">Supported Features</a></li>
<li><a class="reference internal" href="#quickstart">Quickstart</a></li>
<li><a class="reference internal" href="#api-documentation">API Documentation</a></li>
<li><a class="reference internal" href="#technical-constraints">Technical Constraints</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

        </div>
        <div role="main">
        
  <section id="model-compression-toolkit-user-guide">
<span id="ug-index"></span><h1>Model Compression Toolkit User Guide<a class="headerlink" href="#model-compression-toolkit-user-guide" title="Permalink to this heading">¶</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">¶</a></h2>
<p>Model Compression Toolkit (MCT) is an open source project for neural networks optimization that enables users to compress and quantize models.
This project enables researchers, developers and engineers an easily way to optimized and quantized state-of-the-art neural network.</p>
<p>Currently, MCT supports hardware-friendly post training quantization (HPTQ) with Tensorflow 2 [1].</p>
<p>MCT project is developed by researchers and engineers working in Sony Semiconductor Israel.</p>
</section>
<section id="install">
<h2>Install<a class="headerlink" href="#install" title="Permalink to this heading">¶</a></h2>
<p>See the MCT install guide for the pip package, and build from source.</p>
<p>From Source:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">sony</span><span class="o">/</span><span class="n">model_optimization</span><span class="o">.</span><span class="n">git</span>
<span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span>
</pre></div>
</div>
<p>From PyPi - latest stable release:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">model</span><span class="o">-</span><span class="n">compression</span><span class="o">-</span><span class="n">toolkit</span>
</pre></div>
</div>
<p>A nightly version is also available (unstable):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">mct</span><span class="o">-</span><span class="n">nightly</span>
</pre></div>
</div>
<p>For using with Tensorflow please install the packages:
<a class="reference external" href="https://www.tensorflow.org/install">tensorflow</a>
<a class="reference external" href="https://www.tensorflow.org/model_optimization/guide/install">tensorflow-model-optimization</a></p>
<p>For using with Pytorch please install the package:
<a class="reference external" href="https://pytorch.org/">torch</a></p>
</section>
<section id="supported-features">
<h2>Supported Features<a class="headerlink" href="#supported-features" title="Permalink to this heading">¶</a></h2>
<p>Quantization:</p>
<p>Keras:</p>
<ul class="simple">
<li><p><a class="reference internal" href="api/api_docs/methods/keras_post_training_quantization.html#ug-keras-post-training-quantization"><span class="std std-ref">Hardware-friendly Post Training Quantization</span></a> [1]</p></li>
<li><p><a class="reference internal" href="api/experimental_api_docs/classes/GradientPTQConfig.html#ug-gradientptqconfig"><span class="std std-ref">Gradient base post training using knowledge distillation</span></a> (Experimental)</p></li>
<li><p><a class="reference internal" href="api/api_docs/methods/keras_post_training_quantization_mixed_precision.html#ug-keras-post-training-quantization-mixed-precision"><span class="std std-ref">Mixed-precision post training quantization</span></a> (Experimental)</p></li>
<li><p><a class="reference internal" href="api/experimental_api_docs/methods/keras_quantization_aware_training_init.html#ug-keras-quantization-aware-training-init"><span class="std std-ref">Init model for Quantization Aware Training</span></a> (Experimental)</p></li>
<li><p><a class="reference internal" href="api/experimental_api_docs/methods/keras_quantization_aware_training_export.html#ug-keras-quantization-aware-training-finalize"><span class="std std-ref">Finalize model after Quantization Aware Training</span></a> (Experimental)</p></li>
</ul>
<p>Pytorch (Experimental):</p>
<ul class="simple">
<li><p><a class="reference internal" href="api/api_docs/methods/pytorch_post_training_quantization.html#ug-pytorch-post-training-quantization"><span class="std std-ref">Hardware-friendly Post Training Quantization</span></a> [1]</p></li>
<li><p><a class="reference internal" href="api/api_docs/methods/pytorch_post_training_quantization_mixed_precision.html#ug-pytorch-post-training-quantization-mixed-precision"><span class="std std-ref">Mixed-precision post training quantization</span></a></p></li>
</ul>
<p>Visualization:</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="guidelines/visualization.html">Visualization within TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="guidelines/visualization.html#cosine-similarity-comparison">Cosine Similarity Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="guidelines/visualization.html#mixed-precision-configuration-bit-width">Mixed-precision Configuration Bit-width</a></li>
</ul>
</div>
</section>
<section id="quickstart">
<h2>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this heading">¶</a></h2>
<p>Take a look of how you can start using MCT in just a few minutes</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="guidelines/quickstart_keras.html">Quick start tutorial for Keras Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="guidelines/quickstart_pytorch.html">Quick start tutorial for Pytorch Post Training Quantization</a></li>
</ul>
</div>
</section>
<section id="api-documentation">
<h2>API Documentation<a class="headerlink" href="#api-documentation" title="Permalink to this heading">¶</a></h2>
<p>Please visit the MCT API documentation here</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/experimental_api_docs/index.html">API Documentation</a></li>
</ul>
</div>
</section>
<section id="technical-constraints">
<h2>Technical Constraints<a class="headerlink" href="#technical-constraints" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>MCT doesn’t keep the structure of the model’s output. For example, if the output of a model is a list of lists of Tensors [[out1, out2], out3], the optimized model output will be [out1, out2, out3]</p></li>
</ul>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">¶</a></h2>
<p>[1] Habi, H.V., Peretz, R., Cohen, E., Dikstein, L., Dror, O., Diamant, I., Jennings, R.H. and Netzer, A., 2021. <a class="reference external" href="https://arxiv.org/abs/2109.09113">HPTQ: Hardware-Friendly Post Training Quantization. arXiv preprint.</a></p>
</section>
</section>


        </div>
      </div>
    </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2022, Sony Semiconductor Israel.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.1.1.
    </div>
  </body>
</html>